---
layout: post
title: "Summary of 'An Improved Illumination Model for Shaded Display'"
subtitle: "An Improved Illumination Model for Shaded Display (Commun. ACM, 23(6):343â€“349, 1980)"
background: '/assets/post-images/Whitted/fig1.png'
---

# Motivations

- The goal of computer graphics has been achieving photorealism from the beginning. For instance, even the earliest algorithms included shaders that simulated effects such as specular reflection, shadows, and transparency.
- While several works demonstrate the importance of illumination models in practice, existing methods are usually limited in scope since they only focus on light sources and surface orientations (normally represented by normals), ignoring the effect of global illumination.

# Key Contributions

- Proposes a novel rendering method based on physical simulation of light-surface interaction and recursive evaluation of intensities by tracing rays backward from the viewer.

---

# Methods

## Conventional Models

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig1.png">
</center>
<span class="caption text-muted">Figure 1. <b>An example generated by using the method proposed in the paper</b>.</span>

The simpliest visible surface algorithms use shaders based on Lambert's cosine law. According to the law, the intensity of the reflected light is proportional to the dot product of the surface normal and the light source direction. However, note that we can only simluate a perfect diffuser (dull, matte surface) with this simple principle. For more sophiscated effect such as specular reflection which can easily be observed in materials like plastic, or metal, we need to add more terms in our model. One simple, yet powerful solution for simulating specular reflection is proposed by Bui-Tuong Phong in 1975. According to Phong's model, the intensity is computed as:

$$
\begin{gather} 
I = I_{a} + k_{d} \sum_{j=1}^{j=ls} (\bar{N} \cdot \bar{L}_{j}) + k_{s} \sum_{j=1}^{j=ls} (\bar{N} \cdot \bar{L}_{j}^{\prime})^{n},
\end{gather}$$

where $I$ is the reflected intensity, $I_{a}$ is the reflection due to ambient light, $k_{d}$ is the diffuse reflection constant, $\bar{N}$ is the unit surface normal, $\bar{L}\_{j}$ is the vector in the direction of the $j$th light source, $k_{s}$ is the specular reflection coefficient, $\bar{L}\_{j}^{\prime}$ is the direction of halfway vector, and $n$ is an exponent which determines the glossiness of the surface. Note that only the last term is dependent to the viewing direction, and larger $n$ tends to make specular reflection more sharper.

However, Phong's model assumes that each light source is located at a point infinitely far from the objects in the scene, thus do not consider:

1. objects within a scene acting as light sources
2. light reflected from the surface of other objects in the scene

While the model works sufficiently well with diffuse materials, it suffers from serious degrade of quality when it comes to specular reflections. For remedy, Blinn and Newell came up with an idea to tackle the problem by modeling an object's environment and mapping it onto a sphere of infinite radius (the method so called *environment mapping*). However, this approach is not appropriate to apply in the general case.

Not only the specular reflection, but also the simulation of shadows is one of the features that we want an illumination model to support. The principle is still simple - a point on a surface lies in shadow if it is visible to the viewer but not visible to the light source. And various approaches has been proposed to draw more realistic shadows.

Last but not least, transmission of light *through* transparent objects has been simulated by painting surfaces in reverse depth order (i.e., similar to alpha compositing, partially overwrite background). Even though such technique showed impressive results, it could not simulate refraction.

## Improved Model

Then how can we build more realistic model for reflection? What is more physically accurate way to simulate light bouncing off from a point on a surface? Actually, classical ray optics already provides the answer in the case of perfect mirror reflection as illustrated in the figure below.

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig2.png">
</center>
<span class="caption text-muted">Figure 2. <b>Reflection and refraction of a ray at a point on a perfect mirror</b>.</span>

The light intensity $I$ at a point on the surface observed by the viewer is determined by two primary components:

- The specular reflection $S$
- The transmission $T$

these intensities represent light propagated along the $\bar{V}$, $\bar{R}$, and $\bar{P}$ directions, respectively. Additionally, since the surfaces do not only exhibit specularity, we must add a term to model the diffuse component as well. Ideally, the diffuse reflection *should* contain components due to reflection of nearby objects as well as predefined light sources, then the computational cost will be increased dramatically making the rendering infeasible (**Note: considered impossible in 1980, we are now able to simulate such light-surface interaction in real-time after 40 years**). Therefore, the authors adopted the same diffuse model from previous works. Then the newly proposed model is:

$$
\begin{gather}
I = I_{a} + k_{d} \sum_{j=1}^{j=ls} (\bar{N} \cdot \bar{L}_{j}) + k_{s} S + k_{t} T,
\end{gather}
$$

where $S$ is the intensity of light incident from the $\bar{R}$ direction, $k_{t}$ is the transmission coefficient, and $T$ is the intensity of light from the $\bar{P}$ direction. Here, the coefficients $k_{s}$ and $k_{t}$ are held constant for the model, but the authors strongly recommend to regard them as functions each of which is an approximation of the Fresnel reflection law for better quality. In other words, these coefficient should also be dependent to the incidence angle. Even when they are fixed as constants, the actual values of them must be chosen with care in order to generate images that physically make sense.

The direction of reflected ray $\bar{R}$ is determined by the simple rule that the angle of reflection must equal the angle of incident. In similar manner, the direction of transmitted ray $\bar{P}$ can be determined by consulting Snell's law. More specifically, $\bar{R}$ and $\bar{P}$ are functions of $\bar{N}$ and $\bar{V}$ defined as follows:

$$
\begin{gather}
\bar{V}^{\prime} = \frac{\bar{V}}{\vert \bar{V} \cdot \bar{N} \vert}, \\
\bar{R} = \bar{V}^{\prime} + 2 \bar{N}, \\
\bar{P} = k_{f} (\bar{N} + \bar{V}^{\prime}) - \bar{N},
\end{gather}
$$

where $k_{f} = (k_{n}^{2} \vert \bar{V}^{\prime} \vert ^{2} - \vert \bar{V}^{\prime} + \bar{N} \vert^{2})^{-1/2}$ and $k_{n}$ is the index of refraction. Note that these equations assume that $\bar{V} \cdot \bar{N}$ is less than zero, thus the sign of $\bar{N}$ must be adusted so that it points to the side of the surface from the direction which the intersecting ray is coming from. Similarily, the index of refraction must be adjusted to account for the sign change. Furthermore, one can simply assume $T = 0$, total internal reflection is occured when $k_{f}$ becomes imaginary.

One intuition we can obtain from the proposed rule is that the higher $k_{d}$ and the smaller $k_{s}$ will make the surface look less glossy (i.e., matte). This is obvious since we are weighting the diffuse intensity more than that of specular reflection. At the same time, it is worth noting that this method does not use the specular exponent $n$ as Phong's model did. Rather, it is based on the physical observation that it is microscopic mirror-like facets that contribute to the intensity of reflected light in a small region of surface. Of course, one may come up with an idea to consider such irregularity of surface in microscopic scale by introducing random perturbation to surface normals during computation. Considerably small variation will result in glossy surface, while large variation will spread out rays randomly making the surface exhibit diffuse behavior.

Let's turn our attention to more complicated pheonomena - interreflection. The model we discussed until now is nothing but an approximation of light-surface interaction at a surface point. Then one might ask: *"What happens to the reflected or transmitted rays?".* Answering this is the key to understanding *global illumination*, one of the core concepts of modern physically-based rendering techniques.

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig3.png">
</center>
<span class="caption text-muted">Figure 3. <b>Trajectory of light traveling various media</b>.</span>

Imagine a scene having multiple objects and light sources. Let's follow the journey of a light ray starting from one of light sources in the scene. Before reaching the viewer, this ray will bounce off from several surfaces, go through transparent medium, etc. This process can be modeled using well-known tree structure like the figure below.

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig3.png">
</center>
<span class="caption text-muted">Figure 4. <b>Tree representing the trajectory of ray reaching the viewer</b>.</span>

More pricisely, the tree above shows how the ray reaching the viewer from point $A$ in figure 2 is composed of. As one can see in the figure 2, two rays from different directions $T_{1}$ and $S_{1}$ are merged at point $A$, and then go straight to the viewer. However, the ray coming from direction $S_{1}$ is actually the compound of two rays from two directions $S_{2}$ and $T_{2}$. In reality, one can *backtrace* the path of each ray capture by the camera by simply reversing the direction of incident, reflected, and transmitted rays computed in the model discussed earlier. When implemented in the form of algorithm, such procedure can be performed recursively, until meeting the termination condition (e.g., setting the upper bound for the number of recursion, ray travels to free space of nothing, etc).

Additionally, at each step of recursion, especially when computing $\bar{L}\_{j}$ to determine the diffuse reflection, one can determine whether the point is being directly illuminated by lights by casting rays to every light source in the scene and check if there is something between the point and a light source. If so, it implies that the effect of $\bar{L}\_{j}$ must be attenutaed.

## Visible Surface Processor

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig5.png">
</center>
<span class="caption text-muted">Figure 5. <b>Rendering an image by casting rays from each pixel lying on the image plane</b>.</span>

As mentioned earlier, it is much more efficient to trace the rays backward from the viewer to sources, rather than forward tracing the photons emitted from light sources in the scene. This is obviously the desirable choice since only few rays will reach the viewer and contribute to the rendered image. Thus, repeating the earlier discussion, we do the following:

1. Cast a ray from the viewer through a pixel of final image.
2. If a ray intersect a surface of an object in the scene, produce rays in the $\bar{R}$ and $\bar{P}$ direction. Note that it depends on the property of the surface. For example, if the object is not transparent at all, a ray to direction $\bar{P}$ should not be generated.
3. Repeat 1 and 2 for all pixels, until none of generated ray intersect a surface in the scene.

Since one cannot know whether a ray will run into an object or not until following the entire path, the traditional optimization methods such as clipping and back-face culling cannot be used in this scheme. Instead, we can reduce the computation by introducing the concept of bounding volume with which we can test whether the ray intersect an object in the scene quickly. For simplicity, this work first used spheres for rendering since it is easy to perform intersection test and a sphere itself can serve as its own bounding volume. For nonspherical objects, sophiscated intersection processors must be designed for better performance.

- Polygonal surfaces: Solve for the point of intersection of the ray and the plane of the polygon and then check whether the point is on the interior of that polygon.
- Surface consists of bicubic patches: Generate bounding spheres for each patch. If a ray intersect the bounding sphere, subdivide (using the method called *Catmull-Clark subdivision*) the patch and create bounding spheres for each subpatch and perform the same test over and over again.

Moreover, this visible surface algorithm is also able to perform anti-aliasing. In this work, a pixel is defined as the rectangular region whose corners are four sample points as in the figure below.

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig6.png">
</center>
<span class="caption text-muted">Figure 6. <b>A pixel defined as the region surrounded by four sample points</b>. Intensities computed at each sample are almost identical in the case illustrated above.</span>

As shown in the figure above, if the intensities computed at the four corners have nearly equal values, and no small object lies in the region between them, there is no problem. The rendering algorithm may assume that the average of four values is a good approximation for the pixel intensity. However, how about this case?

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig6.png">
</center>
<span class="caption text-muted">Figure 7. <b>An example of inadequate sampling</b>. While three rays intersect the same surface thus yielding similar values, one sampling travels further resulting in dramatically different intensity value.</span>

In such case, the algorithm will subdivide the sample square into more smaller regions and then start over again. This will repeat until the computer runs out of resolution or until the algorithm collects enough information for determining the pixel intensity. And the values from each subregions are weighted according to their area (similar to bilinear interpolation). 

<center>
    <img class="img-fluid" src="/assets/post-images/Whitted/fig6.png">
</center>
<span class="caption text-muted">Figure 8. <b>An example generated by using the method proposed in the paper</b>.</span>

# Conclusion
This paper proposes an illumination model based on techniques suggested by Phong and Blinn. However, instead of adapting previous rendering scheme with little modification, this paper presents a new paradigm of rendering - ray tracing. With ray tracing, global illumination can be simulated realistically by tracing rays generated at each point of intersection while recording the intensities at the same time.

However, this work also needs some improvements:

- Diffuse reflection from distributed light sources
- More realistic specular reflections from less glossy surfaces
- **Runs slowly**