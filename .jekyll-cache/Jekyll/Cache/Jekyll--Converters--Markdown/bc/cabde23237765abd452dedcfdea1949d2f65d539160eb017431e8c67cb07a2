I"E<h1 id="motivations">Motivations</h1>

<ul>
  <li>Reconstructing continuous surfaces from 3D point clouds is a fundamental operation in 3D geometry processing.</li>
  <li>Recent approach using neural network to learn SDF gives promising results → Adopt this idea for 3D point cloud to surface reconstruction.</li>
</ul>

<h1 id="key-contributions">Key Contributions</h1>

<ul>
  <li>Neural-Pull, a simple, new approach for learning SDFs directly from raw 3D point clouds <strong><em>without</em></strong> ground truth signed distance values.</li>
  <li>A network that pulls query 3D point to its closest point on the surface using the predicted SDF values and the gradient at the query point. → Done by network end-to-end</li>
  <li>Effectively learn SDFs by updating the predicted signed distance values and the gradient simultaneously in order to pull surrounding 3D space onto the surface.</li>
  <li>Significant accuracy improvement in surface reconstruction and single image reconstruction.</li>
</ul>

<hr />

<h1 id="method">Method</h1>

<h2 id="problem-statement">Problem Statement</h2>

<p>A neural network for learning SDFs that represent 3D shapes.</p>

<p>An SDF $\boldsymbol{\mathcal{f}}$ predicts a signed distance value $s \in \mathbb{R}$ for a query 3D location $\textbf{q} = [x, y, z]$.</p>

<p>Optionally, one can provide an additional condition $\mathcal{c}$ as input, such that $f(\textbf{c}, \textbf{q}) = s$. Unlike previous approahes <em>(Park et al., 2019; Michalkiewicz et al., 2019)</em> which provided known SDF values during training, <strong>this work aims to learn SDF $f$ in a 3D space directly from 3D point cloud</strong> $\textbf{P} = { \textbf{p}_j, j \in [1, J]}$.</p>

<h2 id="overview">Overview</h2>

<p><img class="img-fluid" src="/assets/post-images/NeuralPull/NeuralPull_fig1.png" />
<span class="caption text-muted">Figure 1. <b>Demonstration of pulling surrounding 2D space onto a surface</b></span></p>

<p><em>Neural-Pull</em> is a neural network that learns how to pull a 3D space onto the surface represented by the point cloud $\textbf{P}$, and eventually learns to represent a SDF $f$.</p>

<p>It uses the given point cloud $\textbf{P}$ and the gradient within the network itself to represent 3D shapes. It tries to learn to pull a query location $q_i$ randomly sampled around the surface to its nearest neighbor $\textbf{t}_i$ on the surface, where the query locations form a set $\textbf{Q} = { \textbf{q}_i, i \in [1, I]}$.</p>

<p>The pulling operation pulls the query location $q_i$ with a stride of signed distance $s_i$, along or against (since the query point can either be inside or outside of the surface) the direction of the gradient $\textbf{g}_i$ at $\textbf{q}_i$, obtained within the network.</p>

<h2 id="pulling-query-points">Pulling Query Points</h2>

<p>A 3D query location $\textbf{q}_i$ is pulled to its nearest neighbor $\textbf{t}_i$ on the surface using the predicted signed distance $s_i$ and the gradient $\textbf{g}_i$ at $\textbf{q}_i$ within the network. The gradient $\textbf{g}_i$ is a vector whose components are the partial derivatives of $f$ at $\textbf{q}_i$, such that,</p>

\[\textbf{g}_i = 
\begin{bmatrix} 
\frac{\partial f (\textbf{c}, \textbf{q}_i)}{\partial x} \\
\frac{\partial f (\textbf{c}, \textbf{q}_i)}{\partial y} \\
\frac{\partial f (\textbf{c}, \textbf{q}_i)}{\partial z}
\end{bmatrix}\]

<p>where $\textbf{q}_i = [x, y, z]$. Note that it’s often denoted as $\nabla f (\textbf{c}, \textbf{q}_i)$, where $\textbf{c}$ is a condition. Mathematically, this is the direction along which the signed distance change is the largest in 3D space. Thus, it’s natural to choose the gradient as the direction for pulling the nearby query point onto the closest point on the surface. Note that the graident $\nabla f$ also serves as a normal vector at a given point due to the characteristic of SDF.</p>

<p>That being said, we can use such property to define ‘pulling’ operation, which pulls a query point $\textbf{q}_i$ onto a point $\textbf{t}_i$, along or against the direction of gradient $\textbf{g}_i$. And the equation is as follows:</p>

\[\textbf{t}_i^{\prime} = \textbf{q}_i - f(\textbf{c}, \textbf{q}_i) \times \frac{\nabla f (\textbf{c}, \textbf{q}_i)}{\left\lVert \nabla f (\textbf{c}, \textbf{q}_i) \right\rVert_{2}}\]

<p>where \(\textbf{t}_i^{\prime}\) is the pulled query point $$ \textbf{q}<em>i$ after pulling, $\textbf{c}$ is the condition to represent ground truth point cloud $\textbf{P}$, and $\nabla f (\textbf{c}, \textbf{q}_i) / \lVert \nabla f (\textbf{c}, \textbf{q}_i) \rVert</em>{2}$ is the unit vector representing the directional component of the gradient $\nabla f (\textbf{c}, \textbf{q}_i)$. Since $f$ is a continuously differentiable function, $\nabla f (\textbf{c}, \textbf{q}_i)$ can be easily obtained via back-propagation.</p>

<p>As shown in the figure 1, there are two possible cases when applying this operation on the query point:</p>

<ol>
  <li>$\textbf{q}<em>i$ inside of the shape $\textbf{P}$: $s_i &lt; 0$, then the operation will pull $\textbf{q}_i$ *along* the direction of gradient such that $\textbf{t}_i^{\prime} = \textbf{q}_i + \vert f (\textbf{c}, \textbf{q}_i)\vert \times \nabla f (\textbf{c}, \textbf{q}_i) / \lVert \nabla f (\textbf{c}, \textbf{q}_i) \rVert</em>{2}$.</li>
  <li>$\textbf{q}<em>i$ outside of the shape $\textbf{P}$: $s_i &gt; 0$, then the operation will pull $\textbf{q}_i$ *against* the direction of gradient such that  $\textbf{t}_i^{\prime} = \textbf{q}_i - \vert f (\textbf{c}, \textbf{q}_i)\vert \times \nabla f (\textbf{c}, \textbf{q}_i) / \lVert \nabla f (\textbf{c}, \textbf{q}_i) \rVert</em>{2}$.</li>
</ol>

<h2 id="query-locations-sampling">Query Locations Sampling</h2>

<p>The query locations are sampled randomly around each point $\textbf{p}<em>j$ of the ground truth point cloud $\textbf{P}$. Specifically, we construct an isotropic Gaussian distribution $\mathcal{N} (\textbf{p}</em>{j}, \sigma^{2})$ for each point $\textbf{p}_j \in \textbf{P}$. Then we sample 25 points from the distribution. Here, the variance $\sigma^{2}$ determines how wide the sample points are spreaded according to the mean point $\textbf{p}_j$.</p>

<p>Particularly, this work used an adaptive way to set $\sigma^{2}$ as the square distance between $\textbf{p}_j$ and its 50-th nearest neighbor. → reflects location density around $\textbf{p}_j$</p>

<p>This adaptive sampling improves the learning accuracy, since it’s hard to predict both SDF value and the corresponding gradient accurately with a point far from the ground truth (which we need to predict) surface.</p>

<h2 id="loss-function">Loss Function</h2>

<p>The goal of the network is to train a network so that it can pull a query location $\textbf{q}_i$ to its nearest neighbor $\textbf{t}_i$ on the point cloud $\textbf{P}$. Thus, one of the effective way to guide the network to learn this behavior is to constrain it on the square error (Euclidean distance between the predicted and ground truth),</p>

\[d(\{ \textbf{t}_{i}^{\prime}\}, \{ \textbf{t}_{i}\}) = \frac{1}{I} \sum_{i \in [1, I]} \lVert \textbf{t}_{i}^{\prime} - \textbf{t}_{i} \rVert_{2}^{2}\]

<p>here, $\textbf{t}<em>{i}^{\prime}$ is the pulled query point obtained by the pulling operation described previously, and $\textbf{t}</em>{i}$ is the nearest neighbor of $\textbf{t}<em>{i}^{\prime}$, which is one of $\textbf{p}</em>{j}$s in the set of points in point cloud $\textbf{P}$.</p>

<h2 id="convergence-to-sdf">Convergence to SDF</h2>

<p>While the idea is fancy and elegant, one important question still remains unanswered.</p>

<p><strong>“Why the learned function $f$ can converge to a <em>signed</em> distance function representing a shape?”</strong></p>

<p>Obviously, the equation of pulling operation is also valid in the case of unsigned distance function. However, there’s a crucial difference between these two in terms of gradient.</p>

<p><img src="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_13.35.45.png" alt="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_13.35.45.png" /></p>

<p>Figure 2. <strong>The illustration of the difference between signed distance field and unsigned distance field</strong>.</p>

<p>In the figure 2, one can easily observe that the gradient of signed distance field has constant value as a query point $\textbf{q}$ moves along a particular direction. Meanwhile, for the case of unsigned distance field, there’s a discontinuity when the $\textbf{q}$ is actually on the surface. Thus, from this observation, we can derive that a continuous function approximated by MLP can automatically converge to an SDF (not uSDF) using the proposed loss.</p>

<blockquote>
  <p><strong>Theorem 1.</strong>
A continuous function $f$ implemented by MLP which is trained to minimize $\ell_2$ loss $d({ \textbf{t}<em>{i}^{\prime}}, { \textbf{t}</em>{i}}) = \frac{1}{I} \sum_{i \in [1, I]} \lVert \textbf{t}<em>{i}^{\prime} - \textbf{t}</em>{i} \rVert_{2}^{2}$, can converge to a signed distance function if the equation $f(\textbf{p} - \textbf{N} \Delta t) = - f (\textbf{p} + \textbf{N} \Delta t)$ is satisfied at any point $\textbf{p}$ on the surface $(f(\textbf{p})=0)$, where $\textbf{N}$ is the normal at $\textbf{p}$, $\lVert \Delta t\rVert &lt; \mu$ and $\mu$ indicates a small number.</p>
</blockquote>

<p><strong>Proof of Theorem 1.</strong>
Since $f$ is a continuous function representing SDF, if $\nabla f(\textbf{p}) \neq \textbf{0}$, the normal at $\textbf{p}$ becomes $\textbf{N} = \nabla f (\textbf{p}) / \lVert \nabla f (\textbf{p}) \rVert_{2}$. Assuming $\Delta \textbf{p} = \textbf{N} \Delta t$ and from the definition of gradient, we have,</p>

\[\lim_{\Delta \textbf{p} \to \textbf{0}} (f (\textbf{p} + \Delta \textbf{p}) - f(\textbf{p})) / \Delta \textbf{p} = \textbf{N} \times \lVert \nabla f (\textbf{p}) \rVert_{2}\]

<p>Then the above can be rewritten by removing $\lim$ and instead introducing infinitesimal $\alpha$,</p>

\[(f (\textbf{p} + \Delta \textbf{p}) - f(\textbf{p})) / \Delta \textbf{p} = \textbf{N} \times \lVert \nabla f (\textbf{p}) \rVert_{2} + \alpha\]

<p>And this can further be modified by multiplying $\Delta \textbf{p} \neq \textbf{0}$ on both sides, obtaining:</p>

\[f(\textbf{p} + \Delta \textbf{p}) - f (\textbf{p}) = (\textbf{N} \times \lVert \nabla f (\textbf{p}) \rVert_{2} + \alpha) \times \Delta \textbf{p}\]

<p>Similarily, we can derive,</p>

\[f(\textbf{p} - \Delta \textbf{p}) - f (\textbf{p}) = -(\textbf{N} \times \lVert \nabla f (\textbf{p}) \rVert_{2} + \alpha) \times \Delta \textbf{p}\]

<p>Since $f(\textbf{p}) = 0$, we finally have:</p>

\[f(\textbf{p} - \Delta \textbf{p}) = - f (\textbf{p} + \Delta \textbf{p})\]

<p>by replacing $\Delta \textbf{p}$ to $\textbf{N} \Delta t$, we can prove the theorem.</p>

<p>🤔 <strong>NOTE: The paper also proves the effectiveness of the loss function that penalizes</strong> $\nabla f (\textbf{p}) = \textbf{0}$. <strong>For details, please refer to the paper.</strong> 🤔</p>

<h2 id="optimization-visualization">Optimization Visualization</h2>

<p><img src="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_14.26.13.png" alt="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_14.26.13.png" /></p>

<p>Figure 3. <strong>Optimization visualization on a 2D case</strong>.</p>

<p>Here’s the description for each of these figure:</p>

<ul>
  <li><strong>(a)</strong>: A circle $\textbf{P}$ that Neural-Pull will learn.</li>
  <li><strong>(b)</strong>: Regions where query points $\textbf{q}_i$s are sampled. Each quadrant is colored to track the pulled points after pulling.</li>
  <li><strong>(c)</strong>: Result of pulling. One can see that Neural-Pull successfully translated query points in the relevant region onto the surface $\textbf{P}$.</li>
  <li><strong>(d)</strong>: Unsigned distance field obtained from the learned signed distance field (taking absolute value will suffice).</li>
  <li><strong>(e)</strong>: Sign of learned signed distance field.</li>
</ul>

<p>The result justifies the effectiveness of the proposed method.</p>

<h2 id="training">Training</h2>

<p>For ground truth, the authors randomly sampled $J = 2 \times 10^{4}$ points $\textbf{p}_{j}$ from point clouds formed by $1 \times 10^{5}$ points released by OccNet.</p>

<p>As mentioned previously, 25 query points $\textbf{q}<em>i$ are sampled (with adaptive sampling strategy) for each point $\textbf{p}</em>{j}$ forming the corresponding query location set $\textbf{Q}$, such that $i \in [1, I]$ and $I = 25 \times J = 5 \times 10^{5}$.</p>

<p>During training, 5000 query points are randomly chosen from $\textbf{Q}$ as a batch to train the network. Two different sampling strategies were examined during the experiment:</p>

<ol>
  <li>Random sample from $\textbf{Q}$</li>
  <li>First uniformly sample 5000 points from $\textbf{P}$, and then select one query point per each sampled point on the ground truth surface.</li>
</ol>

<p>While the second method is expected to perform well since the uniform sampling over the target surface can ensure wider coverage, the experimental results show that both of two ways perform well.</p>

<p>The authors used a neural network similar to OccNet to learn the signed distance function.</p>

<p>Adam optimizer with an initial learning rate of $0.0001$ was used and the network was trained for $2500$ epochs. Furthermore, the network parameters were initialized using the geometric network initialization (GNI) to approximate the signed distance function of a sphere.</p>

<h1 id="experiments-and-analysis">Experiments and Analysis</h1>

<p>🤔 <strong>NOTE: This post only covers a small portion of experimental result (mostly qualitative). For details, please refer to the original paper.</strong> 🤔</p>

<h2 id="surface-reconstruction-from-point-clouds">Surface Reconstruction from Point Clouds</h2>

<p>Neural-Pull was used to reconstruct 3D surfaces from point clouds. Given a point cloud $\textbf{P}$, and in this case the condition $\textbf{c}$ was not used, the neural network was overfitted to the shape. After training, Neural-Pull becomes a neural representation for a shape in 3D, and it’s visualized by applying marching cubes to reconstruct the mesh surface. Below figures show the reconstruction results &amp; comparisons on different datasets.</p>

<p><img src="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.03.25.png" alt="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.03.25.png" /></p>

<p>Figure 4. <strong>Comparison under FAMOUS in surface reconstruction</strong>.</p>

<p><img src="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.03.52.png" alt="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.03.52.png" /></p>

<p>Figure 5. <strong>Comparison under ABC in surface reconstruction</strong>.</p>

<p><img src="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.13.21.png" alt="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.13.21.png" /></p>

<p>Figure 6. <strong>Comparison under ShapeNet in surface reconstruction</strong>.</p>

<h2 id="single-image-reconstruction">Single Image Reconstruction</h2>

<p>This time, Neural-Pull was used to reconstruct 3D shapes from 2D images. Here, the 2D image is considered as a condition $\textbf{c}$, which corresponds to a 3D shape represented as a point cloud $\textbf{P}$. <strong>→ How can we train the network when we don’t have any <em>ground truth points</em>?</strong></p>

<p>During training, a condition and a set of query points $\textbf{Q}$ are used to minimize the loss. And at test time, a 3D shape is reconstructed from an input image with a given condition. For encoding 2D images into features, 2D encoder used by SoftRas (Liu et al., 2019) was used. The result are as follows:</p>

<p><img src="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.24.23.png" alt="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.24.23.png" /></p>

<p>Figure 7. <strong>Single image reconstruction comparison under ShapeNet subset</strong>.</p>

<p><img src="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.24.54.png" alt="Neural-Pull%20Learning%20Signed%20Distance%20Functions%20fro%20f96961f6490f4e3fa4f7c3d85d279df4/_2021-07-05_15.24.54.png" /></p>

<p>Figure 8. <strong>Single image reconstruction results using real world data</strong>.</p>

<h1 id="conclusion">Conclusion</h1>

<ul>
  <li>The paper introduces Neural-Pull, a novel, effective way to learn signed distance functions from 3D point clouds by learning to <em>pull</em> 3D space onto the target surface.</li>
  <li>The network can learn an SDF <strong>without ground truth SDF</strong> by pulling sampled query points to their nearest neighbor on the surface during training.</li>
  <li>Experimental results show that Neural-Pull outperforms state-of-the-art methods in (1) surface reconstruction from 3D point clouds, and (2) single image reconstruction.</li>
</ul>
:ET